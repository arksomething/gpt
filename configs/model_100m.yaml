model:
  vocab_size: 32000
  hidden_size: 768
  intermediate_size: 1792
  num_hidden_layers: 12
  num_attention_heads: 12
  num_key_value_heads: 12
  max_position_embeddings: 2048
  rms_norm_eps: 1.0e-5
  rope_theta: 10000.0
  hidden_act: silu
  attention_bias: false
  mlp_bias: false
  tie_word_embeddings: true
  pad_token_id: 3
  bos_token_id: 1
  eos_token_id: 2
